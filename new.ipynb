{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in file: 1394\n",
      "Unique words in file 310\n"
     ]
    }
   ],
   "source": [
    "#tokens=nltk.word_tokenize(nltk.corpus.gutenberg.raw(nltk.corpus.gutenberg.fileids()[13]))\n",
    "#f=open('/home/meghana/nltk_data/corpora/gutenberg/corpusfile.txt')\n",
    "f=open('/home/meghana/new_jupyter/assign1/Data/Tokenization/Chat1.txt','r')\n",
    "content=f.read()\n",
    "#tokens=content.split()\n",
    "tokens=nltk.word_tokenize(content)\n",
    "tokenSet=set(tokens)\n",
    "print(\"Total words in file:\",len(tokens))\n",
    "print(\"Unique words in file\",len(tokenSet))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in file: 2441004\n",
      "Unique words in file 50345\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for item in tokens:\n",
    "    tokens[i]=item.lower()\n",
    "    tokens[i]=tokens[i].replace('.','').replace(',','').replace(':','').replace(';','').replace('!','').replace('?','').replace('(','').replace(')','')\n",
    "    i=i+1\n",
    "tokenSet=set(tokens)#tokenSet contains unique tokens i.e the vocabulary\n",
    "#filtered_words = [word for word in tokens if word not in stopwords.words('english')]\n",
    "#filtered_words_set=set(filtered_words)\n",
    "#print(len(filtered_words))\n",
    "#print(filtered_words)\n",
    "# print(\"Total words in file:\",len(filtered_words))\n",
    "# print(\"Unique words in file\",len(filtered_words_set))\n",
    "print(\"Total words in file:\",len(tokens))\n",
    "print(\"Unique words in file\",len(tokenSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951851\n"
     ]
    }
   ],
   "source": [
    "quadgrams=list(ngrams(tokens,4))\n",
    "quadgramSet=set(quadgrams)\n",
    "print(len(quadgramSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'collections.Counter'>\n",
      "[('of the lord ', 867), ('the children of israel', 637), (\" '' said the\", 631), (\" '' `` i\", 550), ('the lord  and', 529), (' and i will', 523), (' and all the', 484), ('it came to pass', 457), ('said unto him ', 445), (' and said ', 443)]\n"
     ]
    }
   ],
   "source": [
    "y=[]\n",
    "for item in quadgrams:\n",
    "    new_item=' '.join(item)\n",
    "    y.append(new_item)\n",
    "from collections import Counter\n",
    "x=Counter(y)   \n",
    "print(type(x))\n",
    "print(x.most_common(10))\n",
    "#print(x)\n",
    "#print(x['as soon as she'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The next word is: israel\n",
      "The sentence might be: the children of israel\n"
     ]
    }
   ],
   "source": [
    "s=\"the children of\"\n",
    "freq=0\n",
    "max_freq=0\n",
    "result=0\n",
    "word=0\n",
    "for item in tokenSet:\n",
    "    new_s=s+' '+item\n",
    "    freq=x[new_s]\n",
    "    if(freq>max_freq):\n",
    "        max_freq=freq\n",
    "        result=new_s\n",
    "        word=item\n",
    "print(\"The next word is:\", word)\n",
    "print(\"The sentence might be:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
